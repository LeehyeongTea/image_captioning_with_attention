{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO4IBDrj7iv1gIjKe52jzt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeehyeongTea/image_captioning_with_attention/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QR0i_acqOw-",
        "outputId": "5e2fd7c5-b47c-4a70-9c17-d0afb31094dc"
      },
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Dropout,BatchNormalization,Lambda, Add,Flatten,GRU\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras import regularizers,optimizers,losses,metrics\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "import pickle\n",
        "\n",
        "\n",
        "def get_path(base_directory):\n",
        "  saved_data_path = os.path.join(base_directory,'data')\n",
        "  data_h5_paths = os.path.join(saved_data_path, 'needs.hdf5')\n",
        "  needs = h5py.File(data_h5_paths, 'r')\n",
        "  train_dataset_list_path = needs['train_code_path'][()]\n",
        "  val_dataset_list_path = needs['val_code_path'][()]\n",
        "\n",
        "  train_feature_path = needs['train_feature_path'][()]\n",
        "  val_feature_path = needs['val_feature_path'][()]\n",
        "\n",
        "  train_seq_path= needs['train_seq_path'][()]\n",
        "  val_seq_path= needs['val_seq_path'][()]\n",
        "\n",
        "  max_len = needs['max_len'][()]\n",
        "  vocab_size= needs['vocab_size'][()]\n",
        "  \n",
        "  req_train_list_path = needs['req_train_list_path'][()]\n",
        "  req_val_list_path = needs['req_val_list_path'][()]\n",
        "  req_token_path = needs['req_token_path'][()]\n",
        "  return train_dataset_list_path, val_dataset_list_path, train_feature_path, val_feature_path, train_seq_path,val_seq_path, max_len,vocab_size, req_train_list_path, req_val_list_path, req_token_path\n",
        "\n",
        "\n",
        "def get_data(train_feature_path,train_seq_path, val_feature_path,val_seq_path):\n",
        "  return h5py.File(train_feature_path, 'r'), h5py.File(train_seq_path, 'r'), h5py.File(val_feature_path, 'r'),h5py.File(val_seq_path,'r')\n",
        "\n",
        "#바다나우 어텐션 적용\n",
        "class Attention(Model):\n",
        "  def __init__(self, units, embedding_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "    self.embedding_size = embedding_size\n",
        "    self.units = units\n",
        "  def call(self, values, query):\n",
        "  \n",
        "    query = tf.expand_dims(query,axis = 1)\n",
        "\n",
        "    score = self.V(\n",
        "        tf.nn.tanh(self.W1(values)+ self.W2(query)))\n",
        "    \n",
        "    attention_dist = tf.nn.softmax(score, axis = 1)\n",
        "    context_vector = attention_dist * values\n",
        "    \n",
        "    \n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector,attention_dist\n",
        "  def build(self):\n",
        "    values = Input(shape = (64,2048))\n",
        "    query = Input(shape = (self.units,))\n",
        "    \n",
        "    return Model(inputs=[values, query],outputs = self.call(values, query))\n",
        "\n",
        "\n",
        "class Decoder(Model):\n",
        "  \n",
        "  def __init__(self, max_len, embedding_size, units, vocab_size, reg):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.units = units\n",
        "    self.embedding_size = embedding_size\n",
        "    self.embedding_layer = Embedding(vocab_size, embedding_size,mask_zero = True)\n",
        "    self.lstm = LSTM(units)\n",
        "    self.max_len = max_len\n",
        "    self.attention = Attention(units,embedding_size).build()\n",
        "    self.fc1 = Dense(self.units, activation = 'relu', kernel_regularizer = regularizers.l2(reg))\n",
        "    self.fc2 = Dense(vocab_size, activation = 'softmax', kernel_regularizer = regularizers.l2(reg))\n",
        "  \n",
        "  def call(self, sequence,img, hidden):\n",
        "    \n",
        "    context_vector, attention_dist = self.attention([img, hidden])\n",
        "    sequence = self.embedding_layer(sequence)\n",
        "    \n",
        "    output = self.lstm(sequence)\n",
        "\n",
        "    x = self.fc1(context_vector)\n",
        "\n",
        "    merge = Add()([output, x])\n",
        "    merge = self.fc2(merge)\n",
        "    \n",
        "    return merge,output,attention_dist\n",
        "\n",
        "  def build(self):\n",
        "    sequence = Input(shape = (self.max_len,))\n",
        "    img = Input(shape = (64, 2048))\n",
        "    hidden = Input(shape = (self.units))\n",
        "    return Model(inputs=[sequence, img, hidden],outputs = self.call(sequence,img,hidden))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(decoder,img, text,max_len,\n",
        "               tokenizer,optimizer,compile_loss,train_loss,train_acc):\n",
        "  loss = 0\n",
        "  hidden = tf.zeros((text.shape[0],512))\n",
        "\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    for i in range(1, text.shape[1]):\n",
        "      \n",
        "      input_text = tf.pad(text[:,:i],[[0,0],[0,max_len-i]], \"CONSTANT\")\n",
        "\n",
        "      target = text[:,i]\n",
        "\n",
        "      output,hidden,_ = decoder([input_text, img, hidden])\n",
        "      g_loss = compile_loss(target,output)\n",
        "      loss+=g_loss\n",
        "      train_acc(target,output)\n",
        "\n",
        "  gradients = tape.gradient(loss,\n",
        "                            decoder.trainable_variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients,decoder.trainable_variables))\n",
        "  train_loss(loss/text.shape[1])\n",
        "  \n",
        "\n",
        "@tf.function\n",
        "def test_step(decoder,img, text,max_len,\n",
        "               tokenizer,optimizer,compile_loss,val_loss,val_acc):\n",
        "  loss = 0\n",
        "  hidden = tf.zeros((text.shape[0],512))\n",
        "  \n",
        "  for i in range(1, text.shape[1]):\n",
        "    \n",
        "    input_text = tf.pad(text[:,:i],[[0,0],[0,max_len-i]], \"CONSTANT\")\n",
        "    target = text[:,i]\n",
        "    \n",
        "    output,hidden,_ = decoder([input_text, img, hidden])\n",
        "    g_loss = compile_loss(target,output)\n",
        "    loss+=g_loss\n",
        "    val_acc(target,output)\n",
        "\n",
        "  val_loss(loss/text.shape[1])\n",
        "  \n",
        "\n",
        "\n",
        "def get_feature_x_y(features,seq,elem):\n",
        "  f = features[elem][:]\n",
        "  text = seq[elem][:]\n",
        "  return f,text  \n",
        "\n",
        "\n",
        "def get_saved_data(data_list, feature, seq):\n",
        "  F=list()\n",
        "  T=list()\n",
        "  for elem in data_list:\n",
        "    f,t = get_feature_x_y(feature,seq,elem)\n",
        "    for i in range(len(t)):\n",
        "      F.append(f)\n",
        "      T.append(t[i])\n",
        "     \n",
        "  return np.array(F).squeeze(),np.array(T)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\" :\n",
        "  base_directory = '/content/gdrive/My Drive/Colab Notebooks/image_captioning_with_attention'\n",
        "  train_dataset_list_path, val_dataset_list_path, train_feature_path, val_feature_path, train_seq_path,val_seq_path, max_len,vocab_size, req_train_list_path, req_val_list_path, req_token_path = get_path(base_directory)\n",
        "\n",
        "\n",
        "  with open(req_train_list_path, 'rb') as handle:\n",
        "    train_list = pickle.load(handle)\n",
        "  with open(req_val_list_path,'rb') as handle:\n",
        "    val_list = pickle.load(handle)\n",
        "  with open(req_token_path,'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)       \n",
        "\n",
        "  save_path = os.path.join(base_directory,'merge_model','saved_model')\n",
        "\n",
        "  train_feature, train_seq, val_feature, val_seq= get_data(train_feature_path, train_seq_path,val_feature_path, val_seq_path)\n",
        "\n",
        "\n",
        "  embedding_size = 256\n",
        "  units = 512\n",
        "  reg = 1e-4\n",
        "  \n",
        "\n",
        "  decoder = Decoder(max_len, embedding_size, units, vocab_size,reg).build()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  optimizer = optimizers.Adam()\n",
        "  compile_loss = losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "  train_loss = metrics.Mean()\n",
        "  train_acc = metrics.SparseCategoricalAccuracy()\n",
        "  \n",
        "  val_loss = metrics.Mean()\n",
        "  val_acc = metrics.SparseCategoricalAccuracy()\n",
        "  get_batch_list = list()\n",
        "  \n",
        "  \n",
        "  batch_size = 32\n",
        "\n",
        "  for epoch in range(0,20):\n",
        "    get_batch_list = list()\n",
        "\n",
        "    for i in range(0, len(train_list)):\n",
        "      get_batch_list.append(train_list[i])\n",
        "      if i % batch_size == 0 and i != 0 :\n",
        "        img, text = get_saved_data(get_batch_list, train_feature, train_seq)\n",
        "        train_step(decoder,img,text,max_len,\n",
        "                   tokenizer,optimizer,compile_loss,train_loss,train_acc)\n",
        "        get_batch_list.clear()\n",
        "\n",
        "    if len(get_batch_list) != 0 :\n",
        "      img, text = get_saved_data(get_batch_list, train_feature, train_seq)\n",
        "      train_step(decoder,img,text,max_len,\n",
        "                 tokenizer,optimizer,compile_loss,train_loss,train_acc)\n",
        "      get_batch_list.clear()\n",
        "    \n",
        "    for i in range(0, len(val_list)):\n",
        "      get_batch_list.append(val_list[i])\n",
        "      if i % batch_size == 0 and i != 0 :\n",
        "        img, text = get_saved_data(get_batch_list, val_feature, val_seq)\n",
        "        test_step(decoder,img,text,max_len,\n",
        "                  tokenizer,optimizer,compile_loss,val_loss,val_acc)\n",
        "        get_batch_list.clear()\n",
        "\n",
        "    if len(get_batch_list) != 0 :\n",
        "      img, text = get_saved_data(get_batch_list, val_feature, val_seq,)\n",
        "      test_step(decoder,img,text,max_len,\n",
        "                tokenizer,optimizer,compile_loss,val_loss,val_acc)\n",
        "      get_batch_list.clear()\n",
        "    print('epoch {0:4d} train acc {1:0.3f} loss {2:0.3f} val acc {3:0.3f} loss {4:0.3f}'.\n",
        "          format(epoch, train_acc.result(), train_loss.result(), val_acc.result(), val_loss.result()))\n",
        "    decoder_path = os.path.join(save_path,'decoder_model_{0:02d}_vacc_{1:0.3f}_vloss_{2:0.3f}_acc{3:0.3f}_loss{4:0.3f}.h5'.\n",
        "                        format(epoch, val_acc.result(), val_loss.result(), train_acc.result(), train_loss.result()))\n",
        "    \n",
        "\n",
        "    decoder.save(decoder_path)\n",
        "\n",
        "\n",
        "  train_feature.close()\n",
        "  train_seq.close()\n",
        "  \n",
        "  val_feature.close()\n",
        "  val_seq.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch    0 train acc 0.733 loss 1.710 val acc 0.766 loss 1.332\n",
            "epoch    1 train acc 0.757 loss 1.441 val acc 0.777 loss 1.230\n",
            "epoch    2 train acc 0.770 loss 1.296 val acc 0.783 loss 1.172\n",
            "epoch    3 train acc 0.778 loss 1.198 val acc 0.787 loss 1.137\n",
            "epoch    4 train acc 0.785 loss 1.124 val acc 0.789 loss 1.115\n",
            "epoch    5 train acc 0.790 loss 1.066 val acc 0.791 loss 1.100\n",
            "epoch    6 train acc 0.795 loss 1.019 val acc 0.792 loss 1.092\n",
            "epoch    7 train acc 0.799 loss 0.978 val acc 0.793 loss 1.087\n",
            "epoch    8 train acc 0.803 loss 0.943 val acc 0.794 loss 1.082\n",
            "epoch    9 train acc 0.807 loss 0.911 val acc 0.795 loss 1.079\n",
            "epoch   10 train acc 0.810 loss 0.883 val acc 0.796 loss 1.076\n",
            "epoch   11 train acc 0.813 loss 0.857 val acc 0.796 loss 1.075\n",
            "epoch   12 train acc 0.816 loss 0.833 val acc 0.796 loss 1.075\n",
            "epoch   13 train acc 0.819 loss 0.812 val acc 0.797 loss 1.076\n",
            "epoch   14 train acc 0.822 loss 0.792 val acc 0.797 loss 1.077\n",
            "epoch   15 train acc 0.825 loss 0.774 val acc 0.797 loss 1.080\n",
            "epoch   16 train acc 0.827 loss 0.756 val acc 0.797 loss 1.084\n",
            "epoch   17 train acc 0.830 loss 0.740 val acc 0.797 loss 1.090\n",
            "epoch   18 train acc 0.832 loss 0.724 val acc 0.797 loss 1.095\n",
            "epoch   19 train acc 0.835 loss 0.709 val acc 0.796 loss 1.102\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}